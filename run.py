import os
import argparse

# ã€å…³é”®ã€‘å¿…é¡»åœ¨å¯¼å…¥ torch ä¹‹å‰è®¾ç½® CUDA_VISIBLE_DEVICES
# å¦åˆ™ç¯å¢ƒå˜é‡ä¸ä¼šç”Ÿæ•ˆï¼Œtorch ä¼šä½¿ç”¨æ‰€æœ‰å¯è§çš„ GPU

# ä»å…¨å±€é…ç½®å¯¼å…¥é»˜è®¤è®¾ç½®
try:
    from config import DEFAULT_TARGET_GPUS
except ImportError:
    # å¦‚æœconfig.pyä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å€¼
    DEFAULT_TARGET_GPUS = "2,3"

# å¦‚æœç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œå…ˆè®¾ç½®é»˜è®¤å€¼
# è¿™æ ·å³ä½¿ä½œä¸ºæ¨¡å—å¯¼å…¥ï¼Œä¹Ÿèƒ½æ­£ç¡®è®¾ç½®
if "CUDA_VISIBLE_DEVICES" not in os.environ:
    os.environ["CUDA_VISIBLE_DEVICES"] = DEFAULT_TARGET_GPUS
    print(f"ğŸ”§ è®¾ç½®é»˜è®¤ CUDA_VISIBLE_DEVICES={DEFAULT_TARGET_GPUS} (åœ¨å¯¼å…¥ torch ä¹‹å‰)")

# è®¾ç½®NCCLç¯å¢ƒå˜é‡ä»¥é¿å…è¶…æ—¶
# NCCLè¶…æ—¶æ—¶é—´è®¾ç½®ä¸º60åˆ†é’Ÿï¼ˆ3600000æ¯«ç§’ï¼‰ï¼Œå¢åŠ è¶…æ—¶æ—¶é—´ä»¥é¿å…å¿ƒè·³è¶…æ—¶
os.environ["NCCL_TIMEOUT"] = "3600000"
os.environ["NCCL_IB_TIMEOUT"] = "3600000"
# è®¾ç½®NCCLå¿ƒè·³è¶…æ—¶æ—¶é—´ï¼ˆé»˜è®¤30ç§’ï¼Œå¢åŠ åˆ°5åˆ†é’Ÿï¼‰
os.environ["NCCL_HEARTBEAT_TIMEOUT_SEC"] = "300"
# å¯ç”¨NCCLè°ƒè¯•ï¼ˆå¯é€‰ï¼Œç”¨äºè¯Šæ–­é—®é¢˜ï¼‰
# os.environ["NCCL_DEBUG"] = "INFO"
# ç¦ç”¨NCCLçš„å¼‚æ­¥é”™è¯¯å¤„ç†ï¼Œé¿å…è¿›ç¨‹è¢«æ„å¤–ç»ˆæ­¢
os.environ["TORCH_NCCL_ASYNC_ERROR_HANDLING"] = "0"
print(f"ğŸ”§ è®¾ç½®NCCLè¶…æ—¶æ—¶é—´ä¸º60åˆ†é’Ÿï¼Œå¿ƒè·³è¶…æ—¶ä¸º5åˆ†é’Ÿä»¥é¿å…é€šä¿¡è¶…æ—¶")

# ç°åœ¨å¯ä»¥å®‰å…¨åœ°å¯¼å…¥ torch
import torch

# å¯¼å…¥è®­ç»ƒä¸»å‡½æ•°
# æ”¯æŒä¸¤ç§è®­ç»ƒæ¨¡å¼ï¼šDataParallel (train.py) å’Œ DDP (train-1.py)
try:
    from train import main as dp_main  # DataParallel ç‰ˆæœ¬
    DP_AVAILABLE = True
except ImportError:
    DP_AVAILABLE = False

try:
    from trainddp import main as ddp_main  # DDP ç‰ˆæœ¬
    DDP_AVAILABLE = True
except ImportError:
    DDP_AVAILABLE = False

def single_gpu_train(target_gpu):
    """
    å•å¡è®­ç»ƒæ¨¡å¼ï¼ˆDataParallel æ¨¡å¼ï¼‰
    """
    # æ³¨æ„ï¼šè¿™é‡Œè®¾ç½®å·²ç»å¤ªæ™šäº†ï¼Œtorch å·²ç»åˆå§‹åŒ–
    # å•å¡æ¨¡å¼éœ€è¦é‡æ–°å¯åŠ¨è¿›ç¨‹æ‰èƒ½ç”Ÿæ•ˆ
    print(f"âš ï¸  è­¦å‘Šï¼šå•å¡æ¨¡å¼éœ€è¦åœ¨å¯åŠ¨è„šæœ¬æ—¶è®¾ç½® CUDA_VISIBLE_DEVICES")
    print(f"   ä¾‹å¦‚ï¼šCUDA_VISIBLE_DEVICES={target_gpu} python run.py --mode single --gpu {target_gpu}")
    
    if not torch.cuda.is_available():
        print("âŒ é”™è¯¯ï¼šæœªæ£€æµ‹åˆ° GPUã€‚")
        return
    
    print(f"âœ… [Single] å•å¡è®­ç»ƒæ¨¡å¼å¯åŠ¨ (GPU {target_gpu})")
    print("   ä½¿ç”¨ DataParallel æ¨¡å¼")
    print(f"   å½“å‰å¯è§ GPU æ•°é‡: {torch.cuda.device_count()}")
    
    try:
        dp_main()
    except Exception as e:
        print(f"âŒ è®­ç»ƒé”™è¯¯: {e}")
        raise e
    
    print("\nâœ… å•å¡è®­ç»ƒç»“æŸã€‚")

def multi_gpu_train(target_gpus):
    """
    å¤šå¡ DataParallel è®­ç»ƒæ¨¡å¼
    æ³¨æ„ï¼šDP æ¨¡å¼ä¸éœ€è¦å¤šè¿›ç¨‹ï¼Œtrain.py ä¼šè‡ªåŠ¨ä½¿ç”¨æ‰€æœ‰å¯è§çš„ GPU
    """
    if not DP_AVAILABLE:
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° train.py (DataParallel ç‰ˆæœ¬)")
        print("   è¯·ç¡®ä¿ train.py æ–‡ä»¶å­˜åœ¨")
        return

    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    current_visible = os.environ.get("CUDA_VISIBLE_DEVICES", None)

    if current_visible != target_gpus:
        print(f"âš ï¸  è­¦å‘Š: CUDA_VISIBLE_DEVICES={current_visible}")
        print(f"   æœŸæœ›è®¾ç½®ä¸º: {target_gpus}")
        print(f"   ç¯å¢ƒå˜é‡åœ¨å¯¼å…¥ torch ä¹‹å‰å·²è®¾ç½®ï¼Œå½“å‰å€¼å¯èƒ½æ¥è‡ªé»˜è®¤é…ç½®æˆ–ä¹‹å‰çš„è®¾ç½®")
        print(f"   å¦‚æœè¿™ä¸æ˜¯ä½ æƒ³è¦çš„ï¼Œè¯·åœ¨è¿è¡Œè„šæœ¬å‰è®¾ç½®ç¯å¢ƒå˜é‡ï¼š")
        print(f"   CUDA_VISIBLE_DEVICES={target_gpus} python run.py --gpus {target_gpus}")

    if not torch.cuda.is_available():
        print("âŒ é”™è¯¯ï¼šæœªæ£€æµ‹åˆ° GPUã€‚")
        return

    # è®¡ç®—å®é™…å¯ç”¨å¡æ•°
    n_gpus = torch.cuda.device_count()
    expected_gpus = len(target_gpus.split(','))

    if n_gpus != expected_gpus:
        print(f"âš ï¸  è­¦å‘Šï¼šé…ç½®äº† {expected_gpus} å¼ å¡ ({target_gpus})ï¼Œä½†ç³»ç»Ÿä»…æ£€æµ‹åˆ° {n_gpus} å¼ ã€‚")
        if n_gpus == 0:
            return

    print(f"âœ… [Multi-DP] æ£€æµ‹åˆ° {n_gpus} å¼ å¯ç”¨æ˜¾å¡")
    print(f"   ä½¿ç”¨ DataParallel æ¨¡å¼è¿›è¡Œå¤šå¡è®­ç»ƒ")
    print(f"   é…ç½®çš„ç‰©ç† GPU: {target_gpus}")
    print(f"   å½“å‰ CUDA_VISIBLE_DEVICES: {current_visible}")
    print("----------------------------------------------------------------")

    try:
        # DP æ¨¡å¼ä¸‹ç›´æ¥è°ƒç”¨ main()ï¼Œtrain.py ä¼šè‡ªåŠ¨ä½¿ç”¨ DataParallel åŒ…è£…æ¨¡å‹
        dp_main()
    except Exception as e:
        print(f"\nâŒ DataParallel è®­ç»ƒå‘ç”Ÿå¼‚å¸¸: {e}")
        raise e

def ddp_train(target_gpus):
    """
    å¤šå¡ DDP åˆ†å¸ƒå¼è®­ç»ƒæ¨¡å¼
    æ³¨æ„ï¼šDDP æ¨¡å¼ä½¿ç”¨å¤šè¿›ç¨‹ï¼Œæ¯ä¸ªè¿›ç¨‹è´Ÿè´£ä¸€ä¸ª GPU
    """
    if not DDP_AVAILABLE:
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° trainddp.py (DDP ç‰ˆæœ¬)")
        print("   è¯·ç¡®ä¿ trainddp.py æ–‡ä»¶å­˜åœ¨")
        return

    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    current_visible = os.environ.get("CUDA_VISIBLE_DEVICES", None)

    if current_visible != target_gpus:
        print(f"âš ï¸  è­¦å‘Š: CUDA_VISIBLE_DEVICES={current_visible}")
        print(f"   æœŸæœ›è®¾ç½®ä¸º: {target_gpus}")
        print(f"   ç¯å¢ƒå˜é‡åœ¨å¯¼å…¥ torch ä¹‹å‰å·²è®¾ç½®ï¼Œå½“å‰å€¼å¯èƒ½æ¥è‡ªé»˜è®¤é…ç½®æˆ–ä¹‹å‰çš„è®¾ç½®")
        print(f"   å¦‚æœè¿™ä¸æ˜¯ä½ æƒ³è¦çš„ï¼Œè¯·åœ¨è¿è¡Œè„šæœ¬å‰è®¾ç½®ç¯å¢ƒå˜é‡ï¼š")
        print(f"   CUDA_VISIBLE_DEVICES={target_gpus} python run.py --gpus {target_gpus}")

    if not torch.cuda.is_available():
        print("âŒ é”™è¯¯ï¼šæœªæ£€æµ‹åˆ° GPUã€‚")
        return

    # è®¡ç®—å®é™…å¯ç”¨å¡æ•°
    n_gpus = torch.cuda.device_count()
    expected_gpus = len(target_gpus.split(','))

    if n_gpus != expected_gpus:
        print(f"âš ï¸  è­¦å‘Šï¼šé…ç½®äº† {expected_gpus} å¼ å¡ ({target_gpus})ï¼Œä½†ç³»ç»Ÿä»…æ£€æµ‹åˆ° {n_gpus} å¼ ã€‚")
        if n_gpus == 0:
            return

    print(f"âœ… [Multi-DDP] æ£€æµ‹åˆ° {n_gpus} å¼ å¯ç”¨æ˜¾å¡")
    print(f"   ä½¿ç”¨ DDP åˆ†å¸ƒå¼è®­ç»ƒæ¨¡å¼")
    print(f"   é…ç½®çš„ç‰©ç† GPU: {target_gpus}")
    print(f"   å½“å‰ CUDA_VISIBLE_DEVICES: {current_visible}")
    print("----------------------------------------------------------------")

    try:
        # DDP æ¨¡å¼ä¸‹è°ƒç”¨ ddp_main()ï¼Œå®ƒä¼šè‡ªåŠ¨å¯åŠ¨å¤šè¿›ç¨‹
        ddp_main()
    except Exception as e:
        print(f"\nâŒ DDP è®­ç»ƒå‘ç”Ÿå¼‚å¸¸: {e}")
        raise e

def main_launcher():
    """
    å¯åŠ¨å™¨ä¸»å‡½æ•°
    æ”¯æŒä¸¤ç§æ–¹å¼æŒ‡å®š GPUï¼š
    1. é€šè¿‡å‘½ä»¤è¡Œå‚æ•°ï¼ˆä¼˜å…ˆçº§æ›´é«˜ï¼‰
    2. é€šè¿‡ä»£ç ä¸­çš„é…ç½®åŒºåŸŸï¼ˆé»˜è®¤å€¼ï¼‰
    
    æ³¨æ„ï¼šCUDA_VISIBLE_DEVICES å¿…é¡»åœ¨å¯¼å…¥ torch ä¹‹å‰è®¾ç½®
    å¦‚æœé€šè¿‡å‘½ä»¤è¡Œå‚æ•°æŒ‡å®šäº†ä¸åŒçš„ GPUï¼Œéœ€è¦é‡æ–°å¯åŠ¨è„šæœ¬
    """
    parser = argparse.ArgumentParser(description='PhiSAGE è®­ç»ƒå¯åŠ¨å™¨')
    parser.add_argument('--mode', type=str, choices=['single', 'multi', 'ddp'],
                       help='è®­ç»ƒæ¨¡å¼: single (å•å¡), multi (å¤šå¡DataParallel), ddp (å¤šå¡DDP)')
    parser.add_argument('--gpu', type=str, 
                       help='æŒ‡å®š GPU: å•å¡æ¨¡å¼ä¼ å…¥å•ä¸ªæ•°å­— (å¦‚ "0")ï¼Œå¤šå¡æ¨¡å¼ä¼ å…¥é€—å·åˆ†éš”çš„åˆ—è¡¨ (å¦‚ "0,1,2" æˆ– "4,5,6")')
    parser.add_argument('--gpus', type=str, 
                       help='å¤šå¡æ¨¡å¼çš„ GPU åˆ—è¡¨ (ä¸ --gpu åŠŸèƒ½ç›¸åŒï¼Œç”¨äºå¤šå¡æ¨¡å¼æ›´æ¸…æ™°)')
    
    args = parser.parse_args()
    
    # ================= é…ç½®åŒºåŸŸï¼ˆä»å…¨å±€é…ç½®å¯¼å…¥ï¼‰=================
    # ä»å…¨å±€é…ç½®å¯¼å…¥é»˜è®¤å€¼ï¼Œå‘½ä»¤è¡Œå‚æ•°å¯ä»¥è¦†ç›–è¿™äº›å€¼

    # å¯¼å…¥å…¨å±€é…ç½®
    try:
        from config import DEFAULT_TRAIN_MODE, DEFAULT_SINGLE_GPU_ID
        train_mode = args.mode if args.mode else DEFAULT_TRAIN_MODE
        single_gpu_id = DEFAULT_SINGLE_GPU_ID
    except ImportError:
        # å¦‚æœconfig.pyä¸å­˜åœ¨ï¼Œä½¿ç”¨æœ¬åœ°é»˜è®¤å€¼
        train_mode = args.mode if args.mode else "ddp"
        single_gpu_id = 0

    # å¤šå¡é…ç½® (ä»å…¨å±€é…ç½®å¯¼å…¥)
    target_gpus = DEFAULT_TARGET_GPUS
    
    # ===========================================
    
    # å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é»˜è®¤é…ç½®
    if args.gpu:
        if train_mode == "single":
            try:
                single_gpu_id = int(args.gpu)
            except ValueError:
                print(f"âŒ é”™è¯¯ï¼šå•å¡æ¨¡å¼ä¸‹ --gpu å¿…é¡»æ˜¯å•ä¸ªæ•°å­—ï¼Œå½“å‰å€¼: {args.gpu}")
                return
        else:  # multi mode
            target_gpus = args.gpu
    
    if args.gpus:
        if train_mode == "multi":
            target_gpus = args.gpus
        else:
            print("âš ï¸  è­¦å‘Šï¼š--gpus å‚æ•°ä»…åœ¨ multi æ¨¡å¼ä¸‹æœ‰æ•ˆï¼Œå½“å‰æ¨¡å¼ä¸º singleï¼Œå¿½ç•¥æ­¤å‚æ•°")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦åŒ¹é…
    current_visible = os.environ.get("CUDA_VISIBLE_DEVICES", None)
    if train_mode == "multi" and current_visible != target_gpus:
        print("=" * 60)
        print("âš ï¸  é‡è¦æç¤º")
        print("=" * 60)
        print(f"   å‘½ä»¤è¡ŒæŒ‡å®šäº† GPU: {target_gpus}")
        print(f"   ä½† CUDA_VISIBLE_DEVICES å·²è®¾ç½®ä¸º: {current_visible}")
        print(f"   ç¯å¢ƒå˜é‡åœ¨å¯¼å…¥ torch ä¹‹å‰å·²è®¾ç½®ï¼Œæ— æ³•æ›´æ”¹")
        print(f"   è¦ä½¿ç”¨æŒ‡å®šçš„ GPUï¼Œè¯·é‡æ–°è¿è¡Œï¼š")
        print(f"   CUDA_VISIBLE_DEVICES={target_gpus} python run.py --gpus {target_gpus}")
        print("=" * 60)
        print()
        # ç»§ç»­è¿è¡Œï¼Œä½†ä½¿ç”¨å½“å‰çš„ç¯å¢ƒå˜é‡è®¾ç½®
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    print("=" * 60)
    print("ğŸ“‹ è®­ç»ƒé…ç½®")
    print("=" * 60)
    mode_desc = {
        "single": "å•å¡è®­ç»ƒ",
        "multi": "å¤šå¡ DataParallel",
        "ddp": "å¤šå¡ DDP åˆ†å¸ƒå¼è®­ç»ƒ"
    }
    print(f"   æ¨¡å¼: {train_mode} ({mode_desc.get(train_mode, 'æœªçŸ¥')})")
    if train_mode == "single":
        print(f"   ä½¿ç”¨ GPU: {single_gpu_id}")
    else:
        print(f"   ä½¿ç”¨ GPU: {target_gpus}")
    print(f"   å½“å‰ CUDA_VISIBLE_DEVICES: {current_visible}")

    # æ˜¾ç¤ºå¯ç”¨æ¨¡å¼
    available_modes = []
    if DP_AVAILABLE or DDP_AVAILABLE:
        if DP_AVAILABLE:
            available_modes.append("DataParallel (train.py)")
        if DDP_AVAILABLE:
            available_modes.append("DDP (trainddp.py)")
    print(f"   å¯ç”¨è®­ç»ƒåç«¯: {', '.join(available_modes)}")
    print("=" * 60)
    print()

    if train_mode == "single":
        single_gpu_train(single_gpu_id)
    elif train_mode == "multi":
        multi_gpu_train(target_gpus)
    elif train_mode == "ddp":
        ddp_train(target_gpus)
    else:
        print("âŒ æœªçŸ¥æ¨¡å¼ï¼Œè¯·æ£€æŸ¥ train_mode è®¾ç½®")
        print("   å¯é€‰å€¼: 'single', 'multi', æˆ– 'ddp'")

if __name__ == "__main__":
    # é™åˆ¶ CPU çº¿ç¨‹æ•°ï¼Œé¿å… CPU äº‰æŠ¢
    # æ³¨æ„ï¼šDP æ¨¡å¼æ˜¯å•è¿›ç¨‹å¤šçº¿ç¨‹ï¼Œä¸éœ€è¦åƒ DDP é‚£æ ·ä¸¥æ ¼é™åˆ¶
    # ä½†è®¾ç½®è¿™äº›ç¯å¢ƒå˜é‡ä»ç„¶æœ‰åŠ©äºé¿å…èµ„æºäº‰æŠ¢
    os.environ["OMP_NUM_THREADS"] = "4"  # DP æ¨¡å¼ä¸‹å¯ä»¥é€‚å½“å¢åŠ 
    os.environ["MKL_NUM_THREADS"] = "4"
    
    main_launcher()
